"""
Modelos paramÃ©tricos de sobrevivÃªncia para anÃ¡lise de prÃ©-pagamento
Inclui Weibull, Log-normal, Log-logÃ­stico com covariÃ¡veis
"""

using LinearAlgebra: dot
using SpecialFunctions: loggamma, logbeta, erf, erfc, beta_inc
using Optim: optimize, BFGS, NelderMead, converged, minimizer
using Optim
using Statistics: mean, std, quantile
using Dates: Month

abstract type ParametricSurvivalModel end

function add_l2_regularization(likelihood::Float64, coefficients::Vector{Float64}, 
                              regularization::Float64, exclude_indices::Vector{Int}=[1])::Float64
    """
    Add L2 regularization penalty to likelihood.
    
    Args:
        likelihood: Base log-likelihood value
        coefficients: Model coefficients to regularize
        regularization: Regularization strength (Î»)
        exclude_indices: Indices to exclude from regularization (default: [1] for intercept)
    
    Returns:
        Regularized log-likelihood
    """
    if regularization <= 0.0
        return likelihood
    end
    
    # Apply regularization only to specified coefficients (exclude intercept by default)
    reg_indices = setdiff(1:length(coefficients), exclude_indices)
    reg_penalty = regularization * sum(coefficients[reg_indices].^2)
    
    return likelihood - reg_penalty
end

struct WeibullPrepaymentModel <: ParametricSurvivalModel
    shape::Float64
    scale_coefficients::Vector{Float64}
    covariate_names::Vector{Symbol}
    loglikelihood::Float64
    aic::Float64
    n_observations::Int
    feature_transformer::FeatureTransformer  # Centralized transformer
end

struct LogNormalPrepaymentModel <: ParametricSurvivalModel
    location_coefficients::Vector{Float64}
    scale::Float64
    covariate_names::Vector{Symbol}
    loglikelihood::Float64
    aic::Float64
    n_observations::Int
    feature_transformer::FeatureTransformer  # Centralized transformer
end


struct OptimizedBernoulliBetaModel <: ParametricSurvivalModel
    # Componentes do modelo
    bernoulli_coefficients::Vector{Float64}
    beta_alpha_coefficients::Vector{Float64} 
    beta_beta_coefficients::Vector{Float64}
    
    # Metadados
    covariate_names::Vector{Symbol}
    loglikelihood::Float64
    aic::Float64
    bic::Float64  # BIC para penalizar complexidade
    n_observations::Int
    n_events::Int
    
    # ParÃ¢metros de regularizaÃ§Ã£o
    regularization_strength::Float64
    feature_transformer::FeatureTransformer  # Centralized transformer
end

function fit_parametric_model(data::LoanData;
                             distribution::Symbol=:weibull,
                             covariates::Vector{Symbol}=Symbol[],
                             regularization::Float64=0.01)::ParametricSurvivalModel
    
    @assert distribution in [:weibull, :lognormal, :loglogistic, :bernoulli_beta_optimized]
    
    # Initialize and fit feature transformer
    transformer = FeatureTransformer(covariates)
    fitted_transformer = fit!(transformer, data)
    
    # Transform data using the fitted transformer
    survival_df = _prepare_survival_data_parametric(data, fitted_transformer)
    
    if distribution == :weibull
        return _fit_weibull_model(survival_df, covariates, fitted_transformer, regularization)
    elseif distribution == :lognormal
        return _fit_lognormal_model(survival_df, covariates, fitted_transformer, regularization)
    elseif distribution == :bernoulli_beta_optimized
        return _fit_optimized_bernoulli_beta(data, covariates, regularization, fitted_transformer)
    else
        return _fit_loglogistic_model(survival_df, covariates, fitted_transformer)
    end
end

function _fit_weibull_model(data::DataFrame, covariates::Vector{Symbol}, 
                            fitted_transformer::FeatureTransformer, regularization::Float64=0.01)::WeibullPrepaymentModel
    # Weibull AFT model: log(T) = Î¼ + Ïƒ * Îµ
    # where Î¼ = X'Î² (linear predictor) and Îµ ~ Gumbel(0,1)
    
    n = nrow(data)
    X = _build_design_matrix(data, covariates)
    p = size(X, 2)
    
    # InicializaÃ§Ã£o simples (reverter para valores que funcionavam)
    Î²â‚€ = zeros(p)
    Î²â‚€[1] = 3.0  # Intercept inicial razoÃ¡vel para scale ~20 meses  
    if p > 1
        Î²â‚€[2:end] .= -0.001  # Coeficientes pequenos para covariÃ¡veis
    end
    
    Ïƒâ‚€ = 1.0  # Scale parameter inicial
    Î¸â‚€ = vcat(Î²â‚€, Ïƒâ‚€)  # [Î²..., Ïƒ]
    
    # Maximum Likelihood Estimation usando Optim.jl
    println("      ðŸ”§ Estimando parÃ¢metros via MLE...")
    
    objective(Î¸) = begin
        try
            if Î¸[end] <= 0.01   # Evitar Ïƒ muito pequeno (relaxado)
                return 1e6
            end
            ll = _weibull_loglikelihood(Î¸, data, X)
            regularized_ll = add_l2_regularization(ll, Î¸[1:p], regularization)
            return -regularized_ll
        catch e
            return 1e6  # Retornar valor alto se houver erro numÃ©rico
        end
    end
    
    # OtimizaÃ§Ã£o com constraints mais relaxados
    lower_bounds = vcat(fill(-Inf, p), 0.01)   # Ïƒ > 0.01 (menos restritivo)
    upper_bounds = fill(Inf, p + 1)
    
    # Inicializar variÃ¡veis de resultado
    Î²_hat = Î²â‚€
    Ïƒ_hat = Ïƒâ‚€
    ll = _weibull_loglikelihood(Î¸â‚€, data, X)
    
    try
        # MÃºltiplas estratÃ©gias de otimizaÃ§Ã£o (NÃ­vel 2)
        best_ll = ll
        best_Î¸ = Î¸â‚€
        
        # Strategy 1: Nelder-Mead (robusto)
        result1 = optimize(objective, Î¸â‚€, NelderMead(), Optim.Options(iterations=300))
        if converged(result1) && -minimum(result1) > best_ll
            best_ll = -minimum(result1)
            best_Î¸ = minimizer(result1)
            println("      âœ… Nelder-Mead convergiu! LL=$(round(best_ll, digits=2))")
        end
        
        # Strategy 2: BFGS como backup (se Nelder-Mead falhou)
        if best_ll <= ll + 1.0  # Se nÃ£o melhorou significativamente
            try
                result2 = optimize(objective, Î¸â‚€, BFGS(), Optim.Options(iterations=100))
                if converged(result2) && -minimum(result2) > best_ll
                    best_ll = -minimum(result2)
                    best_Î¸ = minimizer(result2)
                    println("      âœ… BFGS backup convergiu! LL=$(round(best_ll, digits=2))")
                end
            catch
                # BFGS pode falhar, continuar com Nelder-Mead result
            end
        end
        
        # Strategy 3: L-BFGS-B como Ãºltimo recurso
        if best_ll <= ll + 1.0
            try
                result3 = optimize(objective, lower_bounds, upper_bounds, Î¸â‚€, Fminbox(LBFGS()), 
                                 Optim.Options(iterations=150))
                if converged(result3) && -minimum(result3) > best_ll
                    best_ll = -minimum(result3)
                    best_Î¸ = minimizer(result3)
                    println("      âœ… L-BFGS-B convergiu! LL=$(round(best_ll, digits=2))")
                end
            catch
                # L-BFGS-B pode falhar tambÃ©m
            end
        end
        
        # Aplicar melhor resultado encontrado
        if best_ll > ll + 0.1  # Melhoria mÃ­nima requerida
            Î²_hat = best_Î¸[1:p]
            Ïƒ_hat = max(0.01, best_Î¸[end])
            ll = best_ll
        else
            println("      âš ï¸  MLE nÃ£o convergiu adequadamente, usando valores iniciais melhorados")
        end
        
    catch e
        println("      âŒ Erro na otimizaÃ§Ã£o: $e")
        println("      ðŸ”„ Usando valores iniciais")
    end
    
    shape = 1.0 / Ïƒ_hat
    aic = -2 * ll + 2 * (p + 1)
    
    # Store expanded covariate names instead of original ones
    expanded_covariates = PrepaymentModels.get_expanded_covariate_names(covariates)
    
    return WeibullPrepaymentModel(
        shape, Î²_hat, expanded_covariates, ll, aic, n, fitted_transformer
    )
end

function _fit_lognormal_model(data::DataFrame, covariates::Vector{Symbol}, 
                              fitted_transformer::FeatureTransformer, regularization::Float64=0.01)::LogNormalPrepaymentModel
    # Log-normal AFT model: log(T) = Î¼ + Ïƒ * Îµ
    # where Î¼ = X'Î² and Îµ ~ N(0,1)
    
    n = nrow(data)
    X = _build_design_matrix(data, covariates)
    p = size(X, 2)
    
    # Better initial parameter guess using method of moments
    log_times = log.(data.time)
    
    # Initial intercept based on mean log time
    Î²â‚€ = zeros(p)
    Î²â‚€[1] = mean(log_times)
    
    # Initial covariate effects using simple linear regression on log times
    if p > 1
        try
            # Simple OLS on log times as starting point
            y = log_times
            Î²_ols = (X' * X) \ (X' * y)
            Î²â‚€ = Î²_ols
        catch
            Î²â‚€[2:end] .= 0.01 * randn(p-1)
        end
    end
    
    # Initial scale parameter from residuals
    Ïƒâ‚€ = std(log_times - X * Î²â‚€)
    Ïƒâ‚€ = max(0.1, min(2.0, Ïƒâ‚€))  # Reasonable bounds
    
    Î¸â‚€ = vcat(Î²â‚€, Ïƒâ‚€)  # [Î²..., Ïƒ]
    
    println("      ðŸ”§ Estimando parÃ¢metros Log-Normal via MLE...")
    println("      ðŸ“Š InicializaÃ§Ã£o: Î²â‚€[1]=$(round(Î²â‚€[1], digits=3)), Ïƒâ‚€=$(round(Ïƒâ‚€, digits=3))")
    
    # Maximum Likelihood Estimation with better objective function
    objective(Î¸) = begin
        try
            if Î¸[end] <= 0.01 || Î¸[end] > 5.0  # More reasonable bounds for Ïƒ
                return 1e6
            end
            
            # Check for extreme coefficients
            if any(abs.(Î¸[1:p]) .> 10.0)
                return 1e6
            end
            
            ll = _lognormal_loglikelihood(Î¸, data, X)
            
            # Check for valid likelihood
            if !isfinite(ll) || isnan(ll)
                return 1e6
            end
            
            regularized_ll = add_l2_regularization(ll, Î¸[1:p], regularization)
            return -regularized_ll
        catch e
            return 1e6
        end
    end
    
    Î²_hat = Î²â‚€
    Ïƒ_hat = Ïƒâ‚€  
    ll = _lognormal_loglikelihood(Î¸â‚€, data, X)
    
    try
        # Use multiple optimization strategies
        best_ll = ll
        best_Î¸ = Î¸â‚€
        
        # Strategy 1: BFGS with relaxed tolerance
        result1 = optimize(objective, Î¸â‚€, BFGS(), Optim.Options(iterations=150, g_tol=1e-4))
        if converged(result1) && -minimum(result1) > best_ll
            best_ll = -minimum(result1)
            best_Î¸ = minimizer(result1)
        end
        
        # Strategy 2: Nelder-Mead with more iterations
        result2 = optimize(objective, Î¸â‚€, NelderMead(), Optim.Options(iterations=300))
        if converged(result2) && -minimum(result2) > best_ll
            best_ll = -minimum(result2)
            best_Î¸ = minimizer(result2)
        end
        
        if best_ll > ll
            Î²_hat = best_Î¸[1:p]
            Ïƒ_hat = max(0.01, best_Î¸[end])
            ll = best_ll
            println("      âœ… MLE convergiu! LL=$(round(ll, digits=2))")
        else
            println("      âš ï¸  MLE nÃ£o melhorou, usando inicializaÃ§Ã£o inteligente")
        end
        
    catch e
        println("      âŒ Erro na otimizaÃ§Ã£o: $e")
        println("      ðŸ”„ Usando inicializaÃ§Ã£o baseada em momentos")
    end
    
    aic = -2 * ll + 2 * (p + 1)
    
    # Store expanded covariate names instead of original ones
    expanded_covariates = PrepaymentModels.get_expanded_covariate_names(covariates)
    
    return LogNormalPrepaymentModel(
        Î²_hat, Ïƒ_hat, expanded_covariates, ll, aic, n, fitted_transformer
    )
end


function _weibull_loglikelihood(Î¸::Vector{Float64}, data::DataFrame, X::Matrix{Float64})::Float64
    p = size(X, 2)
    Î² = Î¸[1:p]
    Ïƒ = Î¸[end]
    
    @assert Ïƒ > 0 "Scale parameter must be positive"
    
    shape = 1.0 / Ïƒ
    linear_pred = X * Î²
    
    ll = 0.0
    
    for i in 1:nrow(data)
        t = data.time[i]
        Î´ = data.event[i]
        Î¼ = linear_pred[i]
        
        # Weibull survival and hazard
        scale_i = exp(Î¼)
        
        if Î´  # Event observed
            ll += log(shape) - log(scale_i) + (shape - 1) * log(t / scale_i) - (t / scale_i)^shape
        else  # Censored
            ll += -(t / scale_i)^shape
        end
    end
    
    return ll
end

function _lognormal_loglikelihood(Î¸::Vector{Float64}, data::DataFrame, X::Matrix{Float64})::Float64
    p = size(X, 2)
    Î² = Î¸[1:p]
    Ïƒ = Î¸[end]
    
    @assert Ïƒ > 0 "Scale parameter must be positive"
    
    linear_pred = X * Î²
    ll = 0.0
    log_2pi = log(2Ï€)
    
    for i in 1:nrow(data)
        t = data.time[i]
        Î´ = data.event[i]
        Î¼ = linear_pred[i]
        
        # Avoid extreme values
        if t <= 0 || !isfinite(Î¼)
            return -Inf
        end
        
        log_t = log(t)
        z = (log_t - Î¼) / Ïƒ
        
        if Î´  # Event observed - Log-normal PDF
            # log f(t) = -0.5*z^2 - log(t) - log(Ïƒ) - 0.5*log(2Ï€)
            ll += -0.5 * z^2 - log_t - log(Ïƒ) - 0.5 * log_2pi
        else  # Censored - Log-normal survival function
            # S(t) = 1 - Î¦(z) = 0.5 * erfc(z / sqrt(2))
            # Use log-scale for numerical stability
            if z > 5.0  # For large z, S(t) â‰ˆ 0
                ll += -20.0  # Approximate log(very small number)
            elseif z < -5.0  # For small z, S(t) â‰ˆ 1
                ll += -1e-10  # log(1) â‰ˆ 0
            else
                survival_prob = 0.5 * erfc(z / sqrt(2))
                if survival_prob <= 1e-15
                    ll += -35.0  # log(very small number)
                else
                    ll += log(survival_prob)
                end
            end
        end
        
        # Check for numerical issues
        if !isfinite(ll)
            return -Inf
        end
    end
    
    return ll
end

function survival_probability(model::WeibullPrepaymentModel,
                            covariate_values::Dict{Symbol, Float64},
                            time::Float64)::Float64
    
    # Build linear predictor with intercept + covariates
    linear_pred = model.scale_coefficients[1]  # intercept
    
    for (i, var) in enumerate(model.covariate_names)
        if haskey(covariate_values, var)
            linear_pred += model.scale_coefficients[i+1] * covariate_values[var]
        else
            @warn "Missing covariate $var in prediction"
        end
    end
    
    scale = exp(linear_pred)
    shape = model.shape
    
    # Weibull survival function
    return exp(-(time / scale)^shape)
end

function survival_probability(model::LogNormalPrepaymentModel,
                            covariate_values::Dict{Symbol, Float64},
                            time::Float64)::Float64
    
    linear_pred = model.location_coefficients[1]  # Intercept
    for (var, coef) in zip(model.covariate_names, model.location_coefficients[2:end])
        linear_pred += coef * covariate_values[var]
    end
    
    # Simplified survival function without using Distributions
    z = (log(time) - linear_pred) / model.scale
    return 0.5 * (1 - erf(z / sqrt(2)))
end

function hazard_function(model::WeibullPrepaymentModel,
                        covariate_values::Dict{Symbol, Float64},
                        time::Float64)::Float64
    
    linear_pred = 0.0
    for (var, coef) in zip(model.covariate_names, model.scale_coefficients)
        linear_pred += coef * covariate_values[var]
    end
    
    scale = exp(linear_pred)
    shape = model.shape
    
    # Weibull hazard function
    return (shape / scale) * (time / scale)^(shape - 1)
end

function median_survival_time(model::WeibullPrepaymentModel,
                             covariate_values::Dict{Symbol, Float64})::Float64
    
    linear_pred = 0.0
    for (var, coef) in zip(model.covariate_names, model.scale_coefficients)
        linear_pred += coef * covariate_values[var]
    end
    
    scale = exp(linear_pred)
    shape = model.shape
    
    # Weibull median: scale * (log(2))^(1/shape)
    return scale * log(2.0)^(1.0 / shape)
end

function median_survival_time(model::LogNormalPrepaymentModel,
                             covariate_values::Dict{Symbol, Float64})::Float64
    
    linear_pred = model.location_coefficients[1]
    for (var, coef) in zip(model.covariate_names, model.location_coefficients[2:end])
        linear_pred += coef * covariate_values[var]
    end
    
    # Log-normal median: exp(Î¼)
    return exp(linear_pred)
end

function _build_design_matrix(data::DataFrame, covariates::Vector{Symbol})::Matrix{Float64}
    # Use unified expansion function
    expanded_covariates = PrepaymentModels.get_expanded_covariate_names(covariates)
    
    n = nrow(data)
    p = length(expanded_covariates) + 1  # +1 for intercept
    
    X = ones(n, p)  # Initialize with intercept
    
    for (i, var) in enumerate(expanded_covariates)
        var_str = string(var)
        if var_str in names(data)
            X[:, i+1] = data[!, var]
        else
            @warn "Covariate $var not found in DataFrame (available: $(names(data))), using zeros"
            X[:, i+1] .= 0.0
        end
    end
    
    return X
end

function _fit_optimized_bernoulli_beta(data::LoanData, covariates::Vector{Symbol}, regularization::Float64, fitted_transformer::FeatureTransformer)::OptimizedBernoulliBetaModel
    """
    Modelo Bernoulli-Beta com MLE real para parÃ¢metros otimizados
    """
    
    survival_df = _prepare_survival_data_parametric(data, fitted_transformer)
    n = nrow(survival_df)
    X = _build_design_matrix(survival_df, covariates)
    p = size(X, 2)
    
    events = survival_df.event
    n_events = sum(events)
    
    println("   ðŸ”§ Ajustando Bernoulli-Beta com MLE REAL:")
    println("      ðŸ“Š $(n_events) eventos de $(n) observaÃ§Ãµes")
    println("      ðŸŽ¯ RegularizaÃ§Ã£o: $(regularization)")
    
    # Smart initialization using data
    event_rate = n_events / n
    
    # Initialize Bernoulli coefficients using logistic regression
    Î²_bernoulli = zeros(p)
    Î²_bernoulli[1] = log(event_rate / (1 - event_rate))
    if p > 1
        # Use simple correlation-based initialization
        for j in 2:p
            corr_with_events = cor(X[:, j], Float64.(events))
            Î²_bernoulli[j] = 0.5 * corr_with_events  # Scale correlation
        end
    end
    
    # Initialize Beta parameters from timing data
    Î³_Î± = zeros(p)
    Î³_Î² = zeros(p)
    
    # Get timing data for events only
    event_times = survival_df.time[events]
    event_contracts = Float64[]
    
    for i in 1:n
        if events[i]
            loan_idx = findfirst(data.loan_id .== survival_df.loan_id[i])
            contract_length = !isnothing(loan_idx) ? Float64(data.loan_term[loan_idx]) : 36.0
            push!(event_contracts, contract_length)
        end
    end
    
    if length(event_times) > 0
        relative_times = event_times ./ event_contracts
        # Method of moments for Beta distribution
        u_mean = mean(relative_times)
        u_var = var(relative_times)
        
        if u_var > 0 && u_mean > 0 && u_mean < 1
            # Method of moments: Î± = Î¼Â²(1-Î¼)/ÏƒÂ² - Î¼, Î² = Î±(1-Î¼)/Î¼
            common_term = u_mean * (1 - u_mean) / u_var - 1
            Î±_init = u_mean * common_term
            Î²_init = (1 - u_mean) * common_term
            
            Î³_Î±[1] = log(max(0.5, Î±_init))
            Î³_Î²[1] = log(max(0.5, Î²_init))
        else
            Î³_Î±[1] = log(2.0)
            Î³_Î²[1] = log(1.5)
        end
    else
        Î³_Î±[1] = log(2.0)  
        Î³_Î²[1] = log(1.5)
    end
    
    # Small covariate effects for Beta parameters
    if p > 1
        Î³_Î±[2:end] .= 0.01 * randn(p-1)
        Î³_Î²[2:end] .= 0.01 * randn(p-1)
    end
    
    # Combine all parameters
    Î¸â‚€ = vcat(Î²_bernoulli, Î³_Î±, Î³_Î²)  # [Î²..., Î³_Î±..., Î³_Î²...]
    
    println("      ðŸ“Š InicializaÃ§Ã£o inteligente:")
    println("         Bernoulli intercept: $(round(Î²_bernoulli[1], digits=3))")
    println("         Beta Î± intercept: $(round(exp(Î³_Î±[1]), digits=3))")
    println("         Beta Î² intercept: $(round(exp(Î³_Î²[1]), digits=3))")
    
    # MLE Objective function
    function bb_objective(Î¸)
        try
            n_params_each = p
            Î² = Î¸[1:n_params_each]
            Î³_Î±_curr = Î¸[(n_params_each+1):(2*n_params_each)]
            Î³_Î²_curr = Î¸[(2*n_params_each+1):(3*n_params_each)]
            
            # Check parameter bounds
            if any(abs.(Î²) .> 10.0) || any(abs.(Î³_Î±_curr) .> 5.0) || any(abs.(Î³_Î²_curr) .> 5.0)
                return 1e6
            end
            
            ll = _bernoulli_beta_loglikelihood(Î², Î³_Î±_curr, Î³_Î²_curr, data, survival_df, X)
            
            if !isfinite(ll)
                return 1e6
            end
            
            # Add regularization
            reg_penalty = regularization * (sum(Î²[2:end].^2) + sum(Î³_Î±_curr[2:end].^2) + sum(Î³_Î²_curr[2:end].^2))
            
            return -(ll - reg_penalty)  # Negative for minimization
            
        catch e
            return 1e6
        end
    end
    
    # Initial likelihood
    ll_init = _bernoulli_beta_loglikelihood(Î²_bernoulli, Î³_Î±, Î³_Î², data, survival_df, X)
    
    # MLE Optimization
    Î²_hat = Î²_bernoulli
    Î³_Î±_hat = Î³_Î±  
    Î³_Î²_hat = Î³_Î²
    ll_final = ll_init
    
    try
        println("      ðŸ”§ Executando MLE...")
        
        # Strategy 1: BFGS
        result1 = optimize(bb_objective, Î¸â‚€, BFGS(), Optim.Options(iterations=100, g_tol=1e-6))
        
        if converged(result1) && -minimum(result1) > ll_final
            Î¸_opt = minimizer(result1)
            Î²_hat = Î¸_opt[1:p]
            Î³_Î±_hat = Î¸_opt[(p+1):(2*p)]
            Î³_Î²_hat = Î¸_opt[(2*p+1):(3*p)]
            ll_final = -minimum(result1)
            println("      âœ… BFGS MLE convergiu! LL=$(round(ll_final, digits=2))")
        else
            # Strategy 2: Nelder-Mead backup
            result2 = optimize(bb_objective, Î¸â‚€, NelderMead(), Optim.Options(iterations=200))
            if converged(result2) && -minimum(result2) > ll_final
                Î¸_opt = minimizer(result2)
                Î²_hat = Î¸_opt[1:p]
                Î³_Î±_hat = Î¸_opt[(p+1):(2*p)]
                Î³_Î²_hat = Î¸_opt[(2*p+1):(3*p)]
                ll_final = -minimum(result2)
                println("      âœ… Nelder-Mead MLE convergiu! LL=$(round(ll_final, digits=2))")
            else
                println("      âš ï¸  MLE nÃ£o convergiu, usando inicializaÃ§Ã£o inteligente")
            end
        end
        
    catch e
        println("      âŒ Erro na otimizaÃ§Ã£o MLE: $e")
        println("      ðŸ”„ Usando inicializaÃ§Ã£o baseada em dados")
    end
    
    # Add regularization to final likelihood
    reg_penalty = regularization * (sum(Î²_hat[2:end].^2) + sum(Î³_Î±_hat[2:end].^2) + sum(Î³_Î²_hat[2:end].^2))
    ll_regularized = ll_final - reg_penalty
    
    # Information criteria
    n_params = 3 * p
    aic = -2 * ll_regularized + 2 * n_params
    bic = -2 * ll_regularized + log(n) * n_params
    
    println("      ðŸ“Š ParÃ¢metros finais estimados via MLE:")
    println("         Bernoulli intercept: $(round(Î²_hat[1], digits=3))")
    println("         Beta Î± intercept: $(round(exp(Î³_Î±_hat[1]), digits=3))")
    println("         Beta Î² intercept: $(round(exp(Î³_Î²_hat[1]), digits=3))")
    
    # Store expanded covariate names instead of original ones
    expanded_covariates = PrepaymentModels.get_expanded_covariate_names(covariates)
    
    return OptimizedBernoulliBetaModel(
        Î²_hat, Î³_Î±_hat, Î³_Î²_hat, 
        expanded_covariates, ll_regularized, aic, bic, n, n_events,
        regularization, fitted_transformer
    )
end

function _bernoulli_beta_loglikelihood(Î²::Vector{Float64}, Î³_Î±::Vector{Float64}, Î³_Î²::Vector{Float64}, 
                                      data::LoanData, survival_df::DataFrame, X::Matrix{Float64})::Float64
    """
    Log-likelihood para modelo Bernoulli-Beta
    """
    n = nrow(survival_df)
    ll = 0.0
    
    for i in 1:n
        x_i = X[i, :]
        t_i = survival_df.time[i]
        event_i = survival_df.event[i]
        
        # Bernoulli probability (logistic regression)
        logit_p = dot(x_i, Î²)
        if logit_p > 50  # Prevent overflow
            p_prepay = 1.0 - 1e-15
        elseif logit_p < -50
            p_prepay = 1e-15
        else
            p_prepay = 1.0 / (1.0 + exp(-logit_p))
        end
        
        if event_i
            # Find contract length for this loan
            loan_idx = findfirst(data.loan_id .== survival_df.loan_id[i])
            contract_length = !isnothing(loan_idx) ? Float64(data.loan_term[loan_idx]) : 36.0
            
            if t_i <= contract_length && t_i > 0
                # Event within contract - use both Bernoulli and Beta components
                
                # Beta parameters (ensure positive)
                log_Î± = dot(x_i, Î³_Î±)
                log_Î²_param = dot(x_i, Î³_Î²)
                
                Î±_i = exp(min(5.0, max(-5.0, log_Î±)))  # Bounded exp
                Î²_i = exp(min(5.0, max(-5.0, log_Î²_param)))
                
                # Relative time within contract
                u = t_i / contract_length
                u = max(0.001, min(0.999, u))  # Keep in (0,1)
                
                # Beta log-density
                if Î±_i > 0.1 && Î²_i > 0.1 && Î±_i < 100 && Î²_i < 100
                    log_beta_density = (Î±_i - 1) * log(u) + (Î²_i - 1) * log(1 - u) - 
                                      (loggamma(Î±_i) + loggamma(Î²_i) - loggamma(Î±_i + Î²_i))
                    
                    # Combined likelihood: P(prepay) * Beta_density(timing)
                    ll += log(max(1e-15, p_prepay)) + log_beta_density
                else
                    # Fallback if Beta parameters are extreme
                    ll += log(max(1e-15, p_prepay)) - 5.0  # Penalty
                end
            else
                # Event outside contract - shouldn't happen in prepayment context
                ll += log(max(1e-15, 1 - p_prepay))
            end
        else
            # --- InÃ­cio da LÃ³gica Corrigida para Censura ---

            # 1. Obter a duraÃ§Ã£o do contrato para a observaÃ§Ã£o `i`.
            loan_idx = findfirst(data.loan_id .== survival_df.loan_id[i])
            contract_length = !isnothing(loan_idx) ? Float64(data.loan_term[loan_idx]) : 36.0

            # 2. Verificar se a censura ocorre apÃ³s o fim do contrato.
            #    Nesse caso, a probabilidade de prÃ©-pagar depois Ã© zero, e a lÃ³gica antiga se aplica.
            if survival_df.time[i] >= contract_length
                ll += log(max(1e-15, 1 - p_prepay))
            else
                # 3. Se a censura ocorre DURANTE o contrato, calcular a contribuiÃ§Ã£o completa.

                # 3a. Calcular os parÃ¢metros da distribuiÃ§Ã£o Beta (Î±_i, Î²_i) para a observaÃ§Ã£o `i`.
                log_Î± = dot(x_i, Î³_Î±)
                log_Î²_param = dot(x_i, Î³_Î²)
                Î±_i = exp(min(5.0, max(-5.0, log_Î±)))
                Î²_i = exp(min(5.0, max(-5.0, log_Î²_param)))
                
                # 3b. Calcular o tempo relativo de censura `u_i`.
                u_i = survival_df.time[i] / contract_length
                u_i = max(0.001, min(0.999, u_i)) # Manter no intervalo (0, 1)

                # 3c. Calcular a funÃ§Ã£o de sobrevivÃªncia da Beta no ponto u_i.
                #     P(T > u_i) = 1 - CDF_Beta(u_i; Î±_i, Î²_i)
                survival_beta = 1.0 - _beta_cdf(u_i, Î±_i, Î²_i)

                # 3d. Calcular a verossimilhanÃ§a combinada para a observaÃ§Ã£o censurada.
                likelihood_censored = (1 - p_prepay) + p_prepay * survival_beta

                # 3e. Adicionar a contribuiÃ§Ã£o Ã  log-verossimilhanÃ§a total.
                ll += log(max(1e-15, likelihood_censored))
            end
            # --- Fim da LÃ³gica Corrigida para Censura ---
        end
        
        # Check for numerical issues
        if !isfinite(ll)
            return -Inf
        end
    end
    
    return ll
end


# === FUNÃ‡Ã•ES DE PREDIÃ‡ÃƒO ===

function predict_prepayment(model::WeibullPrepaymentModel,
                           data::LoanData,
                           prediction_horizon::Int=36)::Vector{Float64}
    
    n_loans = length(data.loan_id)
    predictions = Vector{Float64}(undef, n_loans)
    
    for i in 1:n_loans
        covariate_dict = transform_single(model.feature_transformer, data, i)
        # Filter to only model covariates
        model_covariates = Dict{Symbol, Float64}()
        for covar_name in model.covariate_names
            if haskey(covariate_dict, covar_name)
                model_covariates[covar_name] = covariate_dict[covar_name]
            else
                model_covariates[covar_name] = 0.0
            end
        end
        covariate_dict = model_covariates
        
        # Calculate survival probability at horizon
        survival_prob = survival_probability(model, covariate_dict, Float64(prediction_horizon))
        
        # Probability of prepayment within horizon
        predictions[i] = 1.0 - survival_prob
    end
    
    return predictions
end

function predict_prepayment(model::LogNormalPrepaymentModel,
                           data::LoanData,
                           prediction_horizon::Int=36)::Vector{Float64}
    
    n_loans = length(data.loan_id)
    predictions = Vector{Float64}(undef, n_loans)
    
    for i in 1:n_loans
        covariate_dict = transform_single(model.feature_transformer, data, i)
        # Filter to only model covariates
        model_covariates = Dict{Symbol, Float64}()
        for covar_name in model.covariate_names
            if haskey(covariate_dict, covar_name)
                model_covariates[covar_name] = covariate_dict[covar_name]
            else
                model_covariates[covar_name] = 0.0
            end
        end
        covariate_dict = model_covariates
        
        # Calculate survival probability at horizon
        survival_prob = survival_probability(model, covariate_dict, Float64(prediction_horizon))
        
        # Probability of prepayment within horizon
        predictions[i] = 1.0 - survival_prob
    end
    
    return predictions
end


function predict_prepayment(model::OptimizedBernoulliBetaModel,
                           data::LoanData,
                           prediction_horizon::Int=36)::Vector{Float64}
    
    n_loans = length(data.loan_id)
    predictions = Vector{Float64}(undef, n_loans)
    
    for i in 1:n_loans
        covariate_dict = transform_single(model.feature_transformer, data, i)
        # Filter to only model covariates
        model_covariates = Dict{Symbol, Float64}()
        for covar_name in model.covariate_names
            if haskey(covariate_dict, covar_name)
                model_covariates[covar_name] = covariate_dict[covar_name]
            else
                model_covariates[covar_name] = 0.0
            end
        end
        covariate_dict = model_covariates
        
        # Build design vector
        x = [1.0]  # Intercept
        for var in model.covariate_names
            push!(x, get(covariate_dict, var, 0.0))
        end
        
        # Bernoulli probability (will prepay at some point)
        logit_p = dot(x, model.bernoulli_coefficients)
        p_prepay = 1.0 / (1.0 + exp(-logit_p))
        
        # Contract duration
        contract_length = Float64(data.loan_term[i])
        
        if prediction_horizon >= contract_length
            # Horizon extends beyond contract end - use full Bernoulli probability
            predictions[i] = p_prepay
        else
            # Horizon is within contract - use Beta component for timing
            
            # Beta parameters
            log_Î± = dot(x, model.beta_alpha_coefficients)
            log_Î²_param = dot(x, model.beta_beta_coefficients)
            
            Î±_i = exp(min(5.0, max(-5.0, log_Î±)))
            Î²_i = exp(min(5.0, max(-5.0, log_Î²_param)))
            
            # Relative horizon within contract
            u_horizon = prediction_horizon / contract_length
            u_horizon = max(0.001, min(0.999, u_horizon))
            
            # P(prepayment by horizon) = P(prepay) Ã— P(timing â‰¤ horizon | prepay)
            # P(timing â‰¤ horizon | prepay) = CDF_Beta(u_horizon; Î±, Î²)
            beta_cdf = _beta_cdf(u_horizon, Î±_i, Î²_i)
            
            predictions[i] = p_prepay * beta_cdf
        end
    end
    
    return predictions
end

function _beta_cdf(x::Float64, Î±::Float64, Î²::Float64)::Float64
    """
    Calculate CDF of Beta distribution using the regularized incomplete beta function I_x(Î±, Î²).
    Relies on a robust implementation from SpecialFunctions.jl.
    """
    if x <= 0.0
        return 0.0
    elseif x >= 1.0
        return 1.0
    elseif Î± <= 0.0 || Î² <= 0.0
        @warn "Beta CDF called with invalid parameters Î±=$Î±, Î²=$Î². Returning fallback."
        return 0.5 # Fallback for invalid parameters
    else
        # I_x(Î±, Î²) = P(X â‰¤ x) where X ~ Beta(Î±, Î²)
        try
            return beta_inc(Î±, Î², x)[1]  # beta_inc returns (I_x, 1-I_x)
        catch e
            @warn "Error calculating beta_inc: $e. Using fallback."
            # Fallback: simple approximation based on mean
            mean_beta = Î± / (Î± + Î²)
            return x < mean_beta ? 0.3 : 0.7
        end
    end
end


function model_comparison(models::Vector{ParametricSurvivalModel})::DataFrame
    comparison = DataFrame(
        Model = String[],
        LogLikelihood = Float64[],
        AIC = Float64[],
        Parameters = Int[],
        Distribution = String[]
    )
    
    for (i, model) in enumerate(models)
        model_name = "Model_$i"
        
        if isa(model, WeibullPrepaymentModel)
            push!(comparison, (
                model_name,
                model.loglikelihood,
                model.aic,
                length(model.scale_coefficients) + 1,
                "Weibull"
            ))
        elseif isa(model, LogNormalPrepaymentModel)
            push!(comparison, (
                model_name,
                model.loglikelihood,
                model.aic,
                length(model.location_coefficients) + 1,
                "LogNormal"
            ))
        elseif isa(model, OptimizedBernoulliBetaModel)
            push!(comparison, (
                model_name,
                model.loglikelihood,
                model.aic,
                3 * length(model.covariate_names) + 3,  # 3 sets of coefficients
                "BB Otimizado"
            ))
        end
    end
    
    # Sort by AIC (lower is better)
    sort!(comparison, :AIC)
    
    return comparison
end

function _prepare_survival_data_parametric(data::LoanData, fitted_transformer::FeatureTransformer)::DataFrame
    n = length(data.loan_id)
    
    # Calculate time to event (months from origination)
    times = Vector{Float64}(undef, n)
    events = Vector{Bool}(undef, n)
    
    for i in 1:n
        if !ismissing(data.prepayment_date[i])
            # Prepayment occurred
            times[i] = _calculate_time_difference_parametric(data.origination_date[i], data.prepayment_date[i])
            events[i] = true
        elseif !ismissing(data.default_date[i])
            # Default occurred (competing risk - censored for prepayment)
            times[i] = _calculate_time_difference_parametric(data.origination_date[i], data.default_date[i])
            events[i] = false
        else
            # Right censored (loan still active or data cutoff)
            times[i] = _calculate_time_difference_parametric(data.origination_date[i], Date(2024, 12, 31))
            events[i] = false
        end
    end
    
    # Use centralized transformer for feature engineering
    df = PrepaymentModels.transform(fitted_transformer, data)
    
    # Add survival data
    df[!, :loan_id] = data.loan_id
    df[!, :time] = times
    df[!, :event] = events
    
    return df
end

function _calculate_time_difference_parametric(start_date::Date, end_date::Date)::Float64
    """
    Calcula diferenÃ§a entre datas em unidades de tempo simplificadas.
    Retorna dias divididos por 30.44 (mÃ©dia de dias por mÃªs) para compatibilidade.
    """
    if end_date <= start_date
        return 0.0
    end
    
    # DiferenÃ§a em dias, convertida para "meses" aproximados 
    days_diff = (end_date - start_date).value
    return Float64(days_diff) / 30.44  # MÃ©dia de dias por mÃªs (365.25/12)
end

